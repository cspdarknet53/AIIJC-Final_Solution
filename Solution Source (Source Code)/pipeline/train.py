# -*- coding: utf-8 -*-
import argparse
import os
import warnings
from argparse import Namespace
from collections import defaultdict
from typing import Dict, List, Tuple

# +
import cv2
import numpy as np
import torch

from torch import nn
from torch.utils.data import DataLoader
from tqdm import tqdm_notebook as tqdm
from pipeline.constants import DEFAULT_EXPERIMENTS_SAVE_PATH, DEFAULT_DATA_PATH, SEED
from pipeline.dataset import get_class2label, get_loaders
from pipeline.models import SignsClassifier
from pipeline.utils import set_global_seed, dump_to_json_file, load_json_file


# -

def parse_args() -> Namespace:
    """Ð¡ommand line argument parser.

    :return: command line arguments
    """
    parser = argparse.ArgumentParser()
    parser.add_argument('--exp_name', type=str, default='baseline')
    parser.add_argument('--model_name', type=str, default='resnet18')
    parser.add_argument('--n_epochs', type=int, default=5)
    parser.add_argument('--batch_size', type=int, default=64)
    parser.add_argument('--device', type=str, default='cuda:0')
    return parser.parse_args()


def train(
    exp_name: str,
    model_name: str,
    n_epochs: int,
    batch_size: int,
    device: str,
    data_path: str = None,
    ep: int = 0,
) -> Tuple[Dict[str, List[float]], Dict[str, List[float]]]:
    """Model training.

    Training the model, checking the model on the validation dataset, getting metrics, saving the best model weights.

    :param exp_name: experiment name
    :param model_name: model name. The available names are described in the pipeline.models.ENCODERS
    :param n_epochs: number of epochs
    :param batch_size: batch size
    :param device: device on which the calculations will be performed
    :return: training and validation metrics
    """
    model, class2label, exp_path, criterion, optimizer = train_initialization(exp_name, model_name, device, data_path)
    best_acc = -np.inf
    ie = 0
    
    if data_path:
        if os.path.exists(os.path.join(DEFAULT_EXPERIMENTS_SAVE_PATH, data_path, f'best{ep}.pth')):
            sdict = torch.load(os.path.join(DEFAULT_EXPERIMENTS_SAVE_PATH, data_path, f'best{ep}.pth'))
            best_acc = sdict['acc']
            ie = sdict['epoch']
            model.load_state_dict(sdict['state_dict'])
            optimizer.load_state_dict(sdict['optimizer_state_dict'])
    train_metrics, valid_metrics = defaultdict(list), defaultdict(list)
    train_loader, valid_loader = get_loaders(DEFAULT_DATA_PATH, batch_size, class2label, num_workers=6)
    for epoch in range(ie, n_epochs):
        epoch_train_metrics = run_one_epoch(epoch, model, train_loader, optimizer, criterion, device, is_train=True)
        update_metrics_by_epoch_metrics(train_metrics, epoch_train_metrics)
        epoch_valid_metrics = run_one_epoch(epoch, model, valid_loader, optimizer, criterion, device, is_train=False)
        update_metrics_by_epoch_metrics(valid_metrics, epoch_valid_metrics)
        curr_acc = epoch_valid_metrics['acc']
        if curr_acc > best_acc:
            best_acc = curr_acc
            torch.save(
                {
                    'state_dict': model.state_dict(),
                    'epoch': epoch,
                    'acc': best_acc,
                    'optimizer_state_dict': optimizer.state_dict(),
                },
                os.path.join(exp_path, f'best{epoch}.pth'),
            )
            print('Model saved!')
    return train_metrics, valid_metrics


def train_initialization(
    exp_name: str,
    model_name: str,
    device: str,
    data_path: str = None,
) -> Tuple[nn.Module, Dict[str, int], str, nn.Module, torch.optim.Optimizer]:
    """Initializing the classes involved in the training.

    :param exp_name: experiment name
    :param model_name: model name. The available names are described in the pipeline.models.ENCODERS
    :param device: device on which the calculations will be performed
    :return: model, class to label dict, experiment path, criterion and optimizer
    """
    prepare2train()
    class2label = get_class2label(DEFAULT_DATA_PATH)
    if data_path is None:
        exp_path = get_and_make_train_dir(exp_name, class2label)
    else:
        exp_path = os.path.join(DEFAULT_EXPERIMENTS_SAVE_PATH, exp_name)
        class2label = load_json_file(os.path.join(exp_path, 'class2label.json'))
    model = SignsClassifier(model_name, len(class2label))
    model.to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer =torch.optim.Adam(model.parameters(), lr=1e-3)
    return model, class2label, exp_path, criterion, optimizer


def prepare2train() -> None:
    """Setting the default values of the system before training."""
    warnings.filterwarnings('ignore')
    cv2.setNumThreads(0)
    cv2.ocl.setUseOpenCL(False)
    set_global_seed(SEED)


def get_and_make_train_dir(exp_name: str, class2label: Dict[str, int]) -> str:
    """Preparing and getting a folder for an experiment.

    :param exp_name: experiment name
    :param class2label: class to label dict
    :return: experiment path
    """
    exp_path = os.path.join(DEFAULT_EXPERIMENTS_SAVE_PATH, exp_name)
    os.makedirs(exp_path, exist_ok=True)
    dump_to_json_file(class2label, os.path.join(exp_path, 'class2label.json'))
    return exp_path


def run_one_epoch(
    epoch: int,
    model: nn.Module,
    loader: DataLoader,
    optimizer: torch.optim.Optimizer,
    criterion: nn.Module,
    device: str,
    is_train: bool = True,
) -> dict:
    """Running a model on a single epoch.

    :param epoch: number of the current epoch
    :param model: model
    :param loader: loader
    :param optimizer: optimizer
    :param criterion: criterion
    :param device: device on which the calculations will be performed
    :param is_train: boolean variable indicating whether it is a training or validation
    :return: metrics on a current epoch
    """
    if is_train:
        model.train()
    else:
        model.eval()
    pbar = tqdm(enumerate(loader), total=len(loader), desc=f'Epoch {epoch} {["evaluate", "train"][is_train]}ing')
    with torch.set_grad_enabled(is_train):
        mean_loss = 0
        mean_acc = 0.
        gt_labels = []
        pred_labels = []
        for num_batch, sample in pbar:
            images, labels = sample['image'], sample['label']
            images = images.to(device)
            predictions = model(images)
            target = labels.to(device)

            loss = criterion(predictions, target)
            mean_loss += loss.item()
            predictions = predictions.argmax(dim=-1).cpu().detach().numpy()
            labels = labels.numpy()
            pred_labels.extend(list(predictions))
            gt_labels.extend(list(labels))
            mean_acc += (labels==predictions).mean()
            if is_train:
                loss.backward()
                optimizer.step()
                optimizer.zero_grad()

            bar_descr = {'loss': f'{mean_loss / (num_batch + 1):.6f}', 'acc': f'{mean_acc/(num_batch+1):.4f}'}
            pbar.set_postfix(**bar_descr)

            del loss, predictions, images, labels, target
        pbar.close()

    prefix = f'{["val", "train"][is_train]}'
    mean_loss /= len(loader)
    mean_acc /= len(loader)
    #f1 = f1_score(gt_labels, pred_labels, average='micro')
    print(f'Epoch {epoch}: {prefix}_acc={mean_acc:.4f}; {prefix}_loss={mean_loss:.6f}')
    return {'acc': mean_acc, 'loss': mean_loss}


def update_metrics_by_epoch_metrics(metrics: Dict[str, List[float]], epoch_metrics: Dict[str, float]) -> None:
    """Updating metrics.

    :param metrics: metrics on all epochs
    :param epoch_metrics: metrics on a single epoch
    :return: updated metrics on all epochs
    """
    for metric_name, metric_vale in epoch_metrics.items():
        metrics[metric_name].append(metric_vale)


if __name__ == '__main__':
    args = parse_args()
    train(args.exp_name, args.model_name, args.n_epochs, args.batch_size, args.device)
